//
// Copyright 2021 The Project Oak Authors
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//

syntax = "proto3";

package oak.functions.abi;

option java_multiple_files = true;
option java_package = "oak.functions.abi";

// A read, write, or wait on a channel returns a ChannelStatus to indicate the success or failure of
// the operation.
enum ChannelStatus {
  CHANNEL_STATUS_UNSPECIFIED = 0;
  // Success.
  CHANNEL_OK = 1;
  // Channel is empty.
  CHANNEL_EMPTY = 2;
}

// A ChannelHandle corresonds to a channel. The Endpoint which does not own the channel uses a
// ChannelHandle to read, write, or wait on the corresponding channel.
enum ChannelHandle {
  CHANNEL_HANDLE_UNSPECIFIED = 0;
  LOOKUP_DATA = 2;
}

// Status values exchanged as i32 values across the Node Wasm interface.
enum OakStatus {
  UNSPECIFIED = 0;
  // Success.
  OK = 1;
  // Arguments invalid.
  ERR_INVALID_ARGS = 2;
  // Internal error.
  ERR_INTERNAL = 3;
  // Lookup storage item not found.
  ERR_STORAGE_ITEM_NOT_FOUND = 4;
  // TensorFlow model not found.
  ERR_TENSOR_FLOW_MODEL_NOT_FOUND = 5;
  // Error when running the TensorFlow model, due to bad input tensor.
  ERR_BAD_TENSOR_FLOW_MODEL_INPUT = 6;
}

// The inference from a TensorFlow model, containing an inference vector of floats, and a shape
// vector specifying the dimensions of the inference vector.
message Inference {
  repeated uint64 shape = 1;
  repeated float inference_vec = 2;
}

// Configuration information that should be provided to the client.
message ConfigurationInfo {
  // Hash of the loaded Wasm module.
  bytes wasm_hash = 1;
  // The validated server-side policy.
  ServerPolicy policy = 2;
  // Whether machine learning inference using a TensorFlow model is enabled.
  bool ml_inference = 3;
  // Server-side configuration for differentially private metrics. This field is optional. If not
  // provided, differentially private metrics are not enabled on the server.
  PrivateMetricsConfig metrics = 4;
}

/// Server-side policy describing limits on the size of the response and response processing time to
/// avoid side-channel leaks.
message ServerPolicy {
  // A fixed size for responses returned by the trusted runtime.
  //
  // This size only applies to the body of the Oak Functions response. If the response body
  // computed by the Wasm module is smaller than this amount, it is padded with additional
  // data before serialization and inclusion in the HTTP response to the client. If the body is
  // larger than this amount, the trusted runtime discards the response and instead uses a
  // response with a body of exactly this size, containing an error message indicating the
  // policy violation. The body included in the HTTP response sent to the client is the binary
  // protobuf encoding of the Oak Functions response, and will have a size larger than
  // `constant_response_size_bytes`. However, this size is still guaranteed to be a constant.
  uint32 constant_response_size_bytes = 1;
  // A fixed response time, in milliseconds.
  //
  // Similar to the previous one, but controls the amount of time the function is allowed to run
  // for. If the function finishes before this time, the response is not sent back until the
  // time is elapsed. If the function does not finish within this deadline, the trusted runtime
  // sends a response to the client containing an error message indicating the failure. The size
  // of this response is equal to the size specified by the previous parameter.
  uint32 constant_processing_time_ms = 2;
}

// Configuration for differentially private metrics.
message PrivateMetricsConfig {
  // The privacy budget.
  double epsilon = 1;
  // The number of requests that will be aggregated into each batch.
  uint32 batch_size = 2;
}
